{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1055ea",
   "metadata": {},
   "source": [
    "# Investigation A (Revisit) & Investigation B (Seasonal LR)\n",
    "\n",
    "This notebook contains a clean, runnable pipeline that performs:\n",
    "\n",
    "- Investigation A (Revisit): cleaning, feature engineering, OLS regression, diagnostics.\n",
    "- Investigation B: merge datasets, seasonal (winter vs spring) LR models, model performance comparison.\n",
    "\n",
    "Place `dataset1.csv` and `dataset2.csv` in the same folder (`/mnt/data`) and run cells in order. Visuals (distribution, boxplots, residuals, performance plots) are included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 1 — Imports & config\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "import statsmodels.api as sm, statsmodels.formula.api as smf\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import mstats\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "OUT = Path('/mnt/data')\n",
    "OUT.mkdir(exist_ok=True)\n",
    "print('Outputs will be saved to', OUT)\n",
    "\n",
    "# User settings\n",
    "FORCE_RESPONSE = None       # set column name to force response for Investigation A\n",
    "WINSORIZE = True\n",
    "WINSOR_PCT = 0.01\n",
    "MIN_ROWS_SEASON = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2 — Load dataset1 and dataset2 (ensure files are in /mnt/data)\n",
    "d1 = OUT / 'dataset1.csv'\n",
    "d2 = OUT / 'dataset2.csv'\n",
    "assert d1.exists(), 'dataset1.csv not found in /mnt/data'\n",
    "assert d2.exists(), 'dataset2.csv not found in /mnt/data'\n",
    "df1 = pd.read_csv(d1)\n",
    "df2 = pd.read_csv(d2)\n",
    "# standardize column names\n",
    "df1.columns = df1.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df2.columns = df2.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "print('df1 shape:', df1.shape, 'df2 shape:', df2.shape)\n",
    "df1.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9444150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 3 — Cleaning & basic feature engineering\n",
    "# Numeric casting\n",
    "nums = ['bat_landing_to_food','seconds_after_rat_arrival','hours_after_sunset','rat_minutes','rat_arrival_number','food_availability','bat_landing_number']\n",
    "for c in nums:\n",
    "    if c in df1.columns: df1[c] = pd.to_numeric(df1[c], errors='coerce')\n",
    "    if c in df2.columns: df2[c] = pd.to_numeric(df2[c], errors='coerce')\n",
    "\n",
    "# Datetime parsing if present\n",
    "for col in ['start_time','rat_period_start','rat_period_end','sunset_time']:\n",
    "    if col in df1.columns:\n",
    "        df1[col] = pd.to_datetime(df1[col], errors='coerce', dayfirst=True)\n",
    "if 'time' in df2.columns:\n",
    "    df2['time'] = pd.to_datetime(df2['time'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# rat_present for df1\n",
    "df1['rat_present'] = np.nan\n",
    "if 'seconds_after_rat_arrival' in df1.columns:\n",
    "    df1.loc[df1['seconds_after_rat_arrival'].notna(), 'rat_present'] = (df1.loc[df1['seconds_after_rat_arrival'].notna(), 'seconds_after_rat_arrival'] >= 0).astype(int)\n",
    "if set(['start_time','rat_period_start','rat_period_end']).issubset(df1.columns):\n",
    "    mask = df1['rat_present'].isna() & df1['start_time'].notna() & df1['rat_period_start'].notna() & df1['rat_period_end'].notna()\n",
    "    df1.loc[mask, 'rat_present'] = ((df1.loc[mask,'start_time'] >= df1.loc[mask,'rat_period_start']) & (df1.loc[mask,'start_time'] <= df1.loc[mask,'rat_period_end'])).astype(int)\n",
    "df1['rat_present'] = df1['rat_present'].fillna(0).astype(int)\n",
    "\n",
    "# vigilance_time\n",
    "if 'bat_landing_to_food' in df1.columns:\n",
    "    df1['vigilance_time'] = df1['bat_landing_to_food'].astype(float)\n",
    "\n",
    "# season_label mapping\n",
    "if 'season' in df1.columns:\n",
    "    df1['season'] = pd.to_numeric(df1['season'], errors='coerce')\n",
    "    df1['season_label'] = df1['season'].map({0:'winter',1:'spring'})\n",
    "else:\n",
    "    df1['season_label'] = df1.get('season_label', pd.NA)\n",
    "\n",
    "# rat_activity_index in df2\n",
    "if set(['rat_arrival_number','rat_minutes']).issubset(df2.columns):\n",
    "    df2['rat_activity_index'] = df2['rat_arrival_number'].fillna(0) * df2['rat_minutes'].fillna(0)\n",
    "elif 'rat_arrival_number' in df2.columns:\n",
    "    df2['rat_activity_index'] = df2['rat_arrival_number'].fillna(0)\n",
    "elif 'rat_minutes' in df2.columns:\n",
    "    df2['rat_activity_index'] = df2['rat_minutes'].fillna(0)\n",
    "else:\n",
    "    df2['rat_activity_index'] = 0\n",
    "\n",
    "print('Cleaning and basic feature engineering done.')\n",
    "df1.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4 — Select response variable and EDA for Investigation A\n",
    "# Choose response: either forced or auto-select based on presence of bat-related columns\n",
    "if FORCE_RESPONSE and FORCE_RESPONSE in df1.columns:\n",
    "    response = FORCE_RESPONSE\n",
    "else:\n",
    "    candidates = [c for c in df1.select_dtypes(include=[np.number]).columns if c not in ['month','season','rat_present','hours_after_sunset']]\n",
    "    response = 'bat_landing_to_food' if 'bat_landing_to_food' in candidates else (candidates[0] if candidates else 'vigilance_time')\n",
    "print('Investigation A response chosen:', response)\n",
    "\n",
    "# Basic descriptives\n",
    "print('Descriptive stats (response):\\n', df1[response].describe())\n",
    "print('\\nBy rat_present:')\n",
    "print(df1.groupby('rat_present')[response].agg(['count','mean','median','std']))\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(df1[response].dropna(), bins=40, kde=True)\n",
    "plt.title(f'Distribution of {response}'); plt.tight_layout(); plt.savefig(OUT/f'{response}_dist.png'); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.boxplot(data=df1, x='rat_present', y=response, showmeans=True)\n",
    "plt.title(f'{response} by rat_present'); plt.tight_layout(); plt.savefig(OUT/f'{response}_by_rat_present.png'); plt.close()\n",
    "print('Saved EDA plots.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04800311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5 — Investigation A: OLS regression + ANOVA\n",
    "predictorsA = [p for p in ['seconds_after_rat_arrival','rat_present','risk','reward','hours_after_sunset'] if p in df1.columns]\n",
    "modA = df1.dropna(subset=[response] + predictorsA).copy()\n",
    "terms = []\n",
    "for c in predictorsA:\n",
    "    if c in ['risk','reward','rat_present']:\n",
    "        terms.append(f'C({c})')\n",
    "    else:\n",
    "        terms.append(c)\n",
    "formulaA = response + ' ~ ' + ' + '.join(terms) if terms else response + ' ~ 1'\n",
    "print('Formula A:', formulaA)\n",
    "modelA = smf.ols(formulaA, data=modA).fit()\n",
    "print(modelA.summary())\n",
    "sm.stats.anova_lm(modelA, typ=2).to_csv(OUT/'investigationA_anova_table.csv')\n",
    "with open(OUT/'investigationA_ols_summary.txt','w') as f: f.write(modelA.summary().as_text())\n",
    "# Diagnostics plots\n",
    "resid = modelA.resid; fitted = modelA.fittedvalues\n",
    "plt.figure(figsize=(6,3)); plt.scatter(fitted, resid, alpha=0.5); plt.axhline(0, color='r', linestyle='--'); plt.title('A: Residuals vs Fitted'); plt.tight_layout(); plt.savefig(OUT/'A_resid_vs_fitted.png'); plt.close()\n",
    "sm.qqplot(resid, line='45'); plt.title('A: QQ'); plt.tight_layout(); plt.savefig(OUT/'A_qq.png'); plt.close()\n",
    "print('Investigation A outputs saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04335d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6 — Merge df1 and df2 for Investigation B\n",
    "merged = df1.copy()\n",
    "if set(['hours_after_sunset','month']).issubset(df1.columns) and set(['hours_after_sunset','month']).issubset(df2.columns):\n",
    "    m1 = df1.sort_values('hours_after_sunset').reset_index(drop=True)\n",
    "    m2 = df2.sort_values('hours_after_sunset').reset_index(drop=True)\n",
    "    try:\n",
    "        merged = pd.merge_asof(m1, m2, on='hours_after_sunset', by='month', direction='nearest', tolerance=0.5, suffixes=('','_sess'))\n",
    "        print('Merged shape:', merged.shape)\n",
    "    except Exception as e:\n",
    "        print('merge_asof failed:', e)\n",
    "        merged = df1.copy()\n",
    "else:\n",
    "    print('Merge not possible; using df1 copy.')\n",
    "\n",
    "merged.to_csv(OUT/'merged_df_for_investigationB.csv', index=False)\n",
    "merged.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 7 — Prepare merged dataset: winsorize, log-transform, interactions, scaling\n",
    "data = merged.copy()\n",
    "response = 'bat_landing_to_food' if 'bat_landing_to_food' in data.columns else 'vigilance_time'\n",
    "data = data[data[response].notna()].copy()\n",
    "data = data[data[response] >= 0]\n",
    "\n",
    "if WINSORIZE:\n",
    "    data[response + '_winsor'] = mstats.winsorize(data[response].fillna(0), limits=(WINSOR_PCT, WINSOR_PCT))\n",
    "else:\n",
    "    data[response + '_winsor'] = data[response].fillna(0)\n",
    "\n",
    "data['y_log'] = np.log1p(data[response + '_winsor'])\n",
    "\n",
    "cont_candidates = ['rat_activity_index','rat_minutes','rat_arrival_number','bat_landing_number','food_availability','hours_after_sunset','seconds_after_rat_arrival']\n",
    "cat_candidates = ['rat_present','risk','reward','habit']\n",
    "\n",
    "predictors = [c for c in cont_candidates + cat_candidates if c in data.columns]\n",
    "\n",
    "if 'rat_activity_index' in data.columns and 'rat_present' in data.columns:\n",
    "    data['ratact_x_ratpresent'] = data['rat_activity_index'] * data['rat_present']\n",
    "    predictors.append('ratact_x_ratpresent')\n",
    "\n",
    "if 'food_availability' in data.columns and 'season' in data.columns:\n",
    "    data['season_num'] = data['season'].map({0:0,1:1}) if 'season' in data.columns else data['season_label'].map({'winter':0,'spring':1})\n",
    "    data['food_x_season'] = data['food_availability'] * data['season_num']\n",
    "    predictors.append('food_x_season')\n",
    "\n",
    "numeric_preds = [p for p in predictors if p in cont_candidates + ['ratact_x_ratpresent','food_x_season','seconds_after_rat_arrival']]\n",
    "scaler = StandardScaler()\n",
    "if numeric_preds:\n",
    "    data[numeric_preds] = scaler.fit_transform(data[numeric_preds].fillna(0))\n",
    "\n",
    "data.to_csv(OUT/'merged_scaled_for_modeling.csv', index=False)\n",
    "print('Prepared merged dataset. predictors:', predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 8 — Backward selection by AIC on y_log\n",
    "def backward_aic(df, response_col, predictors_list, categorical_prefix=None):\n",
    "    best_preds = predictors_list.copy()\n",
    "    categorical_prefix = categorical_prefix or []\n",
    "    def formula(preds):\n",
    "        terms = []\n",
    "        for p in preds:\n",
    "            if p in categorical_prefix:\n",
    "                terms.append(f\"C({p})\")\n",
    "            else:\n",
    "                terms.append(p)\n",
    "        return response_col + ' ~ ' + ' + '.join(terms) if terms else response_col + ' ~ 1'\n",
    "    current_model = smf.ols(formula(best_preds), data=df).fit()\n",
    "    current_aic = current_model.aic\n",
    "    improved = True\n",
    "    while improved and len(best_preds) > 0:\n",
    "        improved = False\n",
    "        candidates = []\n",
    "        for p in best_preds:\n",
    "            trial = [x for x in best_preds if x != p]\n",
    "            try:\n",
    "                m = smf.ols(formula(trial), data=df).fit()\n",
    "                candidates.append((p, m.aic))\n",
    "            except:\n",
    "                candidates.append((p, np.inf))\n",
    "        p_remove, best_aic = min(candidates, key=lambda x: x[1])\n",
    "        if best_aic + 1e-6 < current_aic:\n",
    "            best_preds.remove(p_remove)\n",
    "            current_aic = best_aic\n",
    "            improved = True\n",
    "    return smf.ols(formula(best_preds), data=df).fit(), best_preds\n",
    "\n",
    "categorical_vars = [c for c in ['rat_present','risk','reward','habit'] if c in data.columns]\n",
    "initial_preds = [p for p in predictors if p in data.columns]\n",
    "print('Initial preds:', initial_preds)\n",
    "model_aic, selected_preds = backward_aic(data.dropna(subset=['y_log']), 'y_log', initial_preds, categorical_prefix=categorical_vars)\n",
    "print('Selected preds:', selected_preds)\n",
    "with open(OUT/'investigationB_selected_model_summary.txt','w') as f: f.write(model_aic.summary().as_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac66ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 9 — Final model diagnostics & performance (full)\n",
    "final_model = model_aic\n",
    "print(final_model.summary())\n",
    "\n",
    "resid = final_model.resid; fitted = final_model.fittedvalues\n",
    "plt.figure(figsize=(6,3)); plt.scatter(fitted, resid, alpha=0.5); plt.axhline(0,color='r',linestyle='--'); plt.title('Final model resid vs fitted'); plt.tight_layout(); plt.savefig(OUT/'final_resid_vs_fitted.png'); plt.close()\n",
    "sm.qqplot(resid, line='45'); plt.title('Final model QQ'); plt.tight_layout(); plt.savefig(OUT/'final_qq.png'); plt.close()\n",
    "\n",
    "# VIF\n",
    "try:\n",
    "    exog = final_model.model.exog\n",
    "    vif = pd.DataFrame({'variable': final_model.model.exog_names, 'VIF':[variance_inflation_factor(exog, i) for i in range(exog.shape[1])]})\n",
    "    vif.to_csv(OUT/'final_vif.csv', index=False)\n",
    "except Exception as e:\n",
    "    print('VIF failed:', e)\n",
    "\n",
    "# Performance metrics (safe)\n",
    "y_true_log = data.loc[final_model.model.data.row_labels, 'y_log']\n",
    "y_pred_log = final_model.fittedvalues\n",
    "mask = np.isfinite(y_true_log) & np.isfinite(y_pred_log)\n",
    "if mask.sum() > 0:\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_true_log[mask], y_pred_log[mask]))\n",
    "    r2_log = final_model.rsquared\n",
    "    rmse_orig = np.sqrt(mean_squared_error(np.expm1(y_true_log[mask]), np.expm1(y_pred_log[mask])))\n",
    "    mae_orig = mean_absolute_error(np.expm1(y_true_log[mask]), np.expm1(y_pred_log[mask]))\n",
    "else:\n",
    "    rmse_log = r2_log = rmse_orig = mae_orig = np.nan\n",
    "\n",
    "pd.DataFrame({'metric':['rmse_log','r2_log','rmse_orig','mae_orig'],'value':[rmse_log,r2_log,rmse_orig,mae_orig]}).to_csv(OUT/'final_model_performance.csv', index=False)\n",
    "pd.DataFrame({'coef': final_model.params}).to_csv(OUT/'final_model_coeffs.csv')\n",
    "print('Final model artifacts saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 10 — Seasonal models and performance comparison\n",
    "data['season_label'] = data['season_label'].astype(str)\n",
    "winter_df = data[data['season_label']=='winter'].copy()\n",
    "spring_df = data[data['season_label']=='spring'].copy()\n",
    "print('Winter n=', winter_df.shape[0], 'Spring n=', spring_df.shape[0])\n",
    "\n",
    "season_models = {}\n",
    "for name, df_s in [('winter', winter_df), ('spring', spring_df)]:\n",
    "    if df_s.shape[0] >= MIN_ROWS_SEASON:\n",
    "        terms = [f'C({p})' if p in categorical_vars else p for p in selected_preds]\n",
    "        formula_s = 'y_log ~ ' + ' + '.join(terms) if terms else 'y_log ~ 1'\n",
    "        try:\n",
    "            m = smf.ols(formula_s, data=df_s).fit()\n",
    "            season_models[name] = m\n",
    "            with open(OUT/f'investigationB_ols_{name}_summary.txt','w') as f: f.write(m.summary().as_text())\n",
    "            print(name, 'model R2_log=', m.rsquared)\n",
    "        except Exception as e:\n",
    "            print('Fit failed for', name, e)\n",
    "    else:\n",
    "        print('Not enough rows for', name)\n",
    "\n",
    "# Performance comparison (safe NaN handling)\n",
    "perf_rows = []\n",
    "for name, df_s in [('full', data), ('winter', winter_df), ('spring', spring_df)]:\n",
    "    if name == 'full':\n",
    "        m = final_model\n",
    "        df_use = data.dropna(subset=['y_log'])\n",
    "    else:\n",
    "        m = season_models.get(name)\n",
    "        df_use = df_s.dropna(subset=['y_log'])\n",
    "    if m is None or df_use.empty:\n",
    "        perf_rows.append({'Model':name,'R2_log':np.nan,'RMSE_log':np.nan,'RMSE_orig':np.nan,'NumObs':int(df_use.shape[0])}); continue\n",
    "    y_true_log = df_use['y_log']\n",
    "    y_pred_log = m.predict(df_use)\n",
    "    mask = np.isfinite(y_true_log) & np.isfinite(y_pred_log)\n",
    "    if mask.sum() == 0:\n",
    "        perf_rows.append({'Model':name,'R2_log':np.nan,'RMSE_log':np.nan,'RMSE_orig':np.nan,'NumObs':int(df_use.shape[0])}); continue\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_true_log[mask], y_pred_log[mask]))\n",
    "    rmse_orig = np.sqrt(mean_squared_error(np.expm1(y_true_log[mask]), np.expm1(y_pred_log[mask])))\n",
    "    perf_rows.append({'Model':name,'R2_log':float(m.rsquared),'RMSE_log':float(rmse_log),'RMSE_orig':float(rmse_orig),'NumObs':int(df_use.shape[0])})\n",
    "\n",
    "perf_df = pd.DataFrame(perf_rows)\n",
    "perf_df.to_csv(OUT/'seasonal_model_performance_comparison.csv', index=False)\n",
    "print(perf_df)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(7,4))\n",
    "perf_df.set_index('Model')[['R2_log','RMSE_log']].plot(kind='bar', secondary_y='RMSE_log', rot=0)\n",
    "plt.title('Seasonal Model Performance (R2_log and RMSE_log)'); plt.tight_layout(); plt.savefig(OUT/'seasonal_model_performance_plot.png'); plt.close()\n",
    "print('Seasonal performance plot saved.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8decb422",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "\n",
    "Key outputs saved to `/mnt/data` (or local folder where notebook runs):\n",
    "\n",
    "- investigationA_ols_summary.txt\n",
    "- investigationA_anova_table.csv\n",
    "- final_model_coeffs.csv, final_model_performance.csv\n",
    "- investigationB_ols_winter_summary.txt, investigationB_ols_spring_summary.txt (if generated)\n",
    "- seasonal_model_performance_comparison.csv, seasonal_model_performance_plot.png\n",
    "\n",
    "Run the notebook end-to-end in Jupyter. If column names differ, update predictor lists accordingly."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
